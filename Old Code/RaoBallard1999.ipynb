{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We represent an image of n pixexls by,  $ I = f(Ur) + n$. I is the image, U is a matrix, r is a set of causes, and n is a stochastic process representing devations from the image and the consequences of causes. The colums of U are a basis of the relationship between causes and the images. So we have the the image is a generated by a linear superposition of causes followed by a nonlinearity. \n",
    "\n",
    "Converting this to a neural network, the coeficients $r_j$ are the activities of firing rates of neurons, and the matrix columns $U_j$ are the synaptic weights. The function f(x) is then the neuronal activation function. Then we have that the $r_j$s are the networks representation of the image, interpreted using the internal model defined by the columns of U.\n",
    "\n",
    "We add heirarchy to this model by assuming that the causes r can be represented by a set of higher level causes $r^h$. So we get $ r = r^{td}+n^{td}$, and the top down prediction of r is $r^{td}=f(U^hr^h)$. \n",
    "\n",
    "Assume that the noise terms are Gaussian with zero mean and variances $\\sigma^2$ and $\\sigma_{td}^2$. Then we have the following activation function:\n",
    "\n",
    "$$E_1 = \\frac{1}{\\sigma^2}(I-f(Ur))^T(I-f(Ur))+\\frac{1}{\\sigma_{td}^2}(r-r^{td})^T(r-r^{td})$$\n",
    "\n",
    "which is the negative log of the probability of the data given the parameters. It is the sume of squared prediction errors for level 1 and level 2, with each term being weighted by inverse variance.\n",
    "\n",
    "$$\\mathcal{L}= \\frac{1}{\\sigma^2}|\\textbf{I}-f(\\textbf{U}r)|^2 +  \\frac{1}{\\sigma^2}|r-f(\\textbf{U}^hr^h)|^2   +g(\\textbf{u})+h(r)+g(\\textbf{u})+h(r)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We are going to make a predictive coding model, like from Rao and Ballard 1999\n",
    "# set up the model\n",
    "\n",
    "\n",
    "num_pixels = 128 # number of pixels in the image\n",
    "num_causes = 12 # number of causes\n",
    "num_higher_causes = 8 # number of higher level causes\n",
    "\n",
    "# The input image\n",
    "I = torch.rand(size=(num_pixels,1), requires_grad=True) \n",
    "\n",
    "# The parameters of the model\n",
    "sigma = 0.1\n",
    "sigma_h = 0.2\n",
    "\n",
    "# The lower level causes\n",
    "U = torch.rand(size=(num_pixels, num_causes), requires_grad=True) # the causes basis\n",
    "r = torch.rand(size=(num_causes, 1), requires_grad=True) # representation of the cause of an image\n",
    "\n",
    "# The higher level causes\n",
    "U_h = torch.rand(size=(num_causes, num_higher_causes), requires_grad=True)\n",
    "r_h = torch.rand(size=(num_higher_causes,1), requires_grad=True)\n",
    "\n",
    "precision = 1/(sigma**2)\n",
    "precision_h = 1/(sigma_h**2)\n",
    "f = torch.tanh\n",
    "\n",
    "# The model\n",
    "prediction0 = f(torch.einsum('ij,jk->ik',U,r))\n",
    "prediction_error0 = I - prediction0\n",
    "\n",
    "prediction1 = f(torch.einsum('ij,jk->ik',U_h,r_h))\n",
    "prediction_error1 = r - prediction1\n",
    "\n",
    "log_likelihood = precision*torch.norm(prediction_error0)**2 + \\\n",
    "                precision_h*torch.norm(prediction_error1)**2 \n",
    "\n",
    "log_likelihood.backward()\n",
    "\n",
    "dLdr = r.grad # the gradient of the log likelihood with respect to the representation\n",
    "dLdU = U.grad # the gradient of the log likelihood with respect to the basis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok now we want to load images\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# transform the images so that they are spatially downsampled by a factor of 2\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize((32,32)),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                            shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=False, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2) \n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# Assume that you have a batch of images with shape (batch_size, channels, height, width)\n",
    "batch_size, channels, height, width = images.shape\n",
    "\n",
    "# Define the patch size and stride\n",
    "patch_size = (16, 16)\n",
    "stride = (8, 8)\n",
    "\n",
    "# Extract patches from the images using the patch size and stride\n",
    "patches = images.unfold(2, patch_size[0], stride[0]).unfold(3, patch_size[1], stride[1])\n",
    "\n",
    "# Reshape the patches tensor to have shape (batch_size, patch, channel, height, width)\n",
    "patches = patches.permute(0, 2, 3, 1, 4, 5).contiguous().view(batch_size, -1, channels, patch_size[0], patch_size[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at the first image\n",
    "plt.imshow(np.transpose(images[0], (1, 2, 0)))\n",
    "\n",
    "# look at the patches corresponding to the first image\n",
    "# make sure the grid is the right shape, i.e. square\n",
    "num_patches = int(np.sqrt(patches[0].shape[0]))\n",
    "# make the figure big\n",
    "plt.figure(figsize=(10,10))\n",
    "# make the grid\n",
    "for i in range(num_patches**2):\n",
    "    plt.subplot(num_patches,num_patches,i+1)\n",
    "    plt.imshow(np.transpose(patches[0,i], (1, 2, 0)))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images is of dimension (batch_size, channels, height, width)\n",
    "# patches is of dimension (batch_size, num_patches, channels, patch_size[0], patch_size[1])\n",
    "\n",
    "# now we want to make a predictive coding model, like from Rao and Ballard 1999\n",
    "# set up the model\n",
    "\n",
    "# we will flatten the patches into vectors of dimension (batch_size, num_patches, channels*patch_size[0]*patch_size[1])\n",
    "patches = patches.view(batch_size, -1, channels*patch_size[0]*patch_size[1])\n",
    "\n",
    "# define a torch module for a single patch\n",
    "class PredictiveCodingLevel(nn.Module):\n",
    "    def __init__(self, num_pixels, num_causes, k1, k2, sigma, alpha, lam):\n",
    "        super(PredictiveCodingLevel, self).__init__()\n",
    "        self.num_pixels = num_pixels # number of pixels in the image\n",
    "        self.num_causes = num_causes # number of causes\n",
    "        self.k1 = k1 # learning rate for r\n",
    "        self.k2 = k2 # learning rate for U\n",
    "        self.sigma = sigma # noise level\n",
    "        self.alpha = alpha # weight on the r prior\n",
    "        self.lam = lam # weight on U prior\n",
    "        self.U = nn.Parameter(torch.rand(size=(num_pixels, num_causes)))\n",
    "        # do xavier initialization on U\n",
    "        nn.init.xavier_uniform_(self.U)\n",
    "        self.r = nn.Parameter(torch.zeros(size=(num_causes, 1)))\n",
    "        self.f = torch.tanh\n",
    "        self.precision = 1/(sigma**2)\n",
    "        self.U_prior = torch.norm\n",
    "        self.r_prior = torch.norm\n",
    "\n",
    "        # these are for bookkeeping\n",
    "        self.prediction = None\n",
    "        self.prediction_error = None\n",
    "        self.prediction_loss = None\n",
    "        self.U_prior_loss = None\n",
    "        self.r_prior_loss = None\n",
    "        self.total_loss = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is the input \"image\" which is flattened to a vector of size (1, num_pixels)\n",
    "        prediction = self.f(torch.einsum('ij,jk->ik',self.U,self.r))\n",
    "        prediction_error = x - prediction\n",
    "        prediction_loss = self.precision*torch.norm(prediction_error)**2\n",
    "        U_prior_loss = self.lam*self.U_prior(self.U)\n",
    "        r_prior_loss = self.alpha*self.r_prior(self.r)\n",
    "\n",
    "        # update internal values\n",
    "        self.prediction = prediction\n",
    "        self.prediction_error = prediction_error\n",
    "        self.prediction_loss = prediction_loss\n",
    "        self.U_prior_loss = U_prior_loss\n",
    "        self.r_prior_loss = r_prior_loss\n",
    "        self.total_loss = prediction_loss + U_prior_loss + r_prior_loss\n",
    "\n",
    "        return self.r\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 9, 768])\n",
      "torch.Size([4, 6912])\n",
      "Iteration:    0 | Batch:    0 | Loss: 13141662.00000 | U max:    0.02935 | r max: 4659.74316\n",
      "Iteration:   10 | Batch:    0 | Loss: 65442884.00000 | U max: 2364378.25000 | r max: 2899.07666\n",
      "Iteration:   20 | Batch:    0 | Loss: 60603448.00000 | U max: 2364378.25000 | r max: 1735.47595\n",
      "Iteration:   30 | Batch:    0 | Loss: 58928376.00000 | U max: 2364378.25000 | r max: 1038.78528\n",
      "Iteration:   40 | Batch:    0 | Loss: 58521048.00000 | U max: 2364378.25000 | r max:  621.65063\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13852\\51951586.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\adamimos\\anaconda3\\envs\\priors\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\adamimos\\anaconda3\\envs\\priors\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\adamimos\\anaconda3\\envs\\priors\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13852\\3741187049.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mU_prior_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mU_prior_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr_prior_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr_prior_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mU_prior_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mr_prior_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# Assume that you have a batch of images with shape (batch_size, channels, height, width)\n",
    "batch_size, channels, height, width = images.shape\n",
    "\n",
    "# Define the patch size and stride\n",
    "patch_size = (16, 16)\n",
    "stride = (8, 8)\n",
    "\n",
    "# Extract patches from the images using the patch size and stride, shape is \n",
    "patches = images.unfold(2, patch_size[0], stride[0]).unfold(3, patch_size[1], stride[1])\n",
    "\n",
    "# Reshape the patches tensor to have shape (batch_size, patch, channel, height, width)\n",
    "patches = patches.permute(0, 2, 3, 1, 4, 5).contiguous().view(batch_size, -1, channels, patch_size[0], patch_size[1])\n",
    "\n",
    "# flatten the patches into shape (batch_size, num_patches, channels*patch_size[0]*patch_size[1])\n",
    "patches = patches.view(batch_size, -1, channels*patch_size[0]*patch_size[1])\n",
    "print(patches.shape)\n",
    "\n",
    "# now take all patches and make them into a single vector, final shape is (batch_size, num_patches*channels*patch_size[0]*patch_size[1])\n",
    "patches = patches.view(batch_size, -1)\n",
    "print(patches.shape)\n",
    "\n",
    "batch_size, num_pixels = patches.shape\n",
    "\n",
    "# define the model, it will be two PredictiveCodingLevel modules\n",
    "# the first will have num_causes = 100, and the second will have num_causes = 200\n",
    "model = nn.Sequential(PredictiveCodingLevel(num_pixels, 50, k1=0.5, k2=.1, sigma=np.sqrt(1), alpha=1, lam=0.02), \n",
    "                            PredictiveCodingLevel(50, 100, k1=0.5, k2=.1, sigma=np.sqrt(10), alpha=0.05, lam=0.02))\n",
    "\n",
    "# for each image in the batch, run the model for 100 timesteps\n",
    "for i in range(batch_size):\n",
    "    for t in range(1000):\n",
    "        output = model(patches[i])\n",
    "\n",
    "\n",
    "        #  define loss as the sum of total loss from all layers of the model\n",
    "        loss = sum([layer.total_loss for layer in model])\n",
    "\n",
    "        #backpropagate the loss\n",
    "        loss.backward()\n",
    "\n",
    "        # compute the gradients with respect to U and r for each layer\n",
    "        U_gradients = [layer.U.grad for layer in model]\n",
    "        r_gradients = [layer.r.grad for layer in model]\n",
    "\n",
    "        # update the parameters with the gradients\n",
    "        #  if iterations < 500 only do this for layer 1\n",
    "        # else do for both\n",
    "\n",
    "        model[0].U.data += -model[0].k2/2*model[0].U.grad\n",
    "        model[0].r.data += -model[0].k1/2*model[0].r.grad\n",
    "        model[1].U.data += -model[1].k2/2*model[1].U.grad\n",
    "        model[1].r.data += -model[1].k1/2*model[1].r.grad\n",
    "\n",
    "        # zero out the gradients for the entire model\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # every 10 iterations, print out the loss\n",
    "        # but also print out the iteration, the batch number, and the abs max of U and r\n",
    "        # and keep it very neat\n",
    "        if t % 10 == 0:\n",
    "            print(\"Iteration: {:4d} | Batch: {:4d} | Loss: {:10.5f} | U max: {:10.5f} | r max: {:10.5f}\".format(t, i, loss.item(), model[0].U.max().item(), model[0].r.max().item()))\n",
    "\n",
    "        # every 40 iterations, divide k2 by 1.015\n",
    "        if t % 40 == 39:\n",
    "            for layer in model:\n",
    "                layer.k2 /= 1.015\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U max:  tensor(2.6712e+08)\n",
      "r max:  tensor(1.7499e+10)\n",
      "U max:  tensor(27689968.)\n",
      "r max:  tensor(657.3454)\n"
     ]
    }
   ],
   "source": [
    "# print max U and r values\n",
    "for layer in model:\n",
    "    print('U max: ', torch.max(layer.U.data))\n",
    "    print('r max: ', torch.max(layer.r.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U gradients\n",
      "min:  tensor(-6.0823e+10)\n",
      "max:  tensor(6.0823e+10)\n",
      "layer 0\n",
      "prediction loss:  tensor(1.4597e+09, grad_fn=<MulBackward0>)\n",
      "U prior loss:  tensor(14.0404, grad_fn=<CopyBackwards>)\n",
      "r prior loss:  tensor(0., grad_fn=<CopyBackwards>)\n",
      "mean abs prediction error:  tensor(0.5301, grad_fn=<MeanBackward0>)\n",
      "precision:  99.99999999999999\n",
      "layer 1\n",
      "prediction loss:  tensor(2.1307e+22, grad_fn=<MulBackward0>)\n",
      "U prior loss:  tensor(11.5392, grad_fn=<CopyBackwards>)\n",
      "r prior loss:  tensor(0., grad_fn=<CopyBackwards>)\n",
      "mean abs prediction error:  tensor(1.4597e+09, grad_fn=<MeanBackward0>)\n",
      "precision:  99.99999999999999\n"
     ]
    }
   ],
   "source": [
    "#  define loss as the sum of total loss from all layers of the model\n",
    "loss = sum([layer.total_loss for layer in model])\n",
    "\n",
    "#backpropagate the loss\n",
    "loss.backward()\n",
    "\n",
    "# compute the gradients with respect to U and r for each layer\n",
    "U_gradients = [layer.U.grad for layer in model]\n",
    "r_gradients = [layer.r.grad for layer in model]\n",
    "\n",
    "# print the min and max gradiets\n",
    "print('U gradients')\n",
    "print('min: ', min([torch.min(U) for U in U_gradients]))\n",
    "print('max: ', max([torch.max(U) for U in U_gradients]))\n",
    "\n",
    "# update the parameters with the gradients\n",
    "for i, layer in enumerate(model):\n",
    "    layer.U.data -= .001*layer.U.grad\n",
    "    layer.r.data -= .00001*layer.r.grad\n",
    "\n",
    "# for each layer in the model, print out the 3 losses and the mean abs prediction error\n",
    "# also print the precision\n",
    "for i, layer in enumerate(model):\n",
    "    print('layer %d' % i)\n",
    "    print('prediction loss: ', layer.prediction_loss)\n",
    "    print('U prior loss: ', layer.U_prior_loss)\n",
    "    print('r prior loss: ', layer.r_prior_loss)\n",
    "    print('mean abs prediction error: ', torch.mean(torch.abs(layer.prediction_error)))\n",
    "    print('precision: ', layer.precision)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min input:  tensor(0.0588)\n",
      "max input:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# wprint out the min and max of the inputs\n",
    "print('min input: ', patches.min())\n",
    "print('max input: ', patches.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "priors",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c4afa5a5f73812c269159ae70f4b7edad95d7caec0fa45bd129c72c54ccf567"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
